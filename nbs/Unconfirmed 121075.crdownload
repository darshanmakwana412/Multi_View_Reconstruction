{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e6190a-2c40-4719-a88a-459aabdf18eb",
   "metadata": {},
   "source": [
    "### Keypoints and Feature Descriptors Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63a85c75-2a9d-4f71-af39-2836bf870c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4846f4e08eaf466a8e01d1ca47126201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing Object Views from Images:   0%|          | 0/570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class ObjView:\n",
    "    def __init__(self, image_path: str) -> None:\n",
    "        self.root_dir = \"/\".join(image_path.split(\"/\")[:-1])\n",
    "        self.img_name = int(image_path.split(\"/\")[-1][:-4])\n",
    "        self.img_array = cv2.imread(image_path)\n",
    "        self.kp = None\n",
    "        self.desc = None\n",
    "        self.R = np.eye(3, 3)\n",
    "        self.t = np.zeros((3, 1), dtype=np.float32)\n",
    "\n",
    "    def detectFeatures(self, detector: cv2.SIFT) -> None:\n",
    "        keypoints_dir = os.path.join(self.root_dir, \"keypoints\")\n",
    "        desc_dir = os.path.join(self.root_dir, \"descriptors\")\n",
    "        os.makedirs(keypoints_dir, exist_ok=True)\n",
    "        os.makedirs(desc_dir, exist_ok=True)\n",
    "\n",
    "        keypoints_path = os.path.join(keypoints_dir, f\"{self.img_name}_keypoints.npy\")\n",
    "        desc_path = os.path.join(desc_dir, f\"{self.img_name}_descriptors.npy\")\n",
    "\n",
    "        if os.path.exists(keypoints_path) and os.path.exists(desc_path):\n",
    "            self.kp, self.desc = self.load(keypoints_path, desc_path)\n",
    "        else:\n",
    "            self.kp, self.desc = detector.detectAndCompute(self.img_array, None)\n",
    "            self.save(keypoints_path, desc_path)\n",
    "\n",
    "    def save(self, keypoints_path: str, desc_path: str) -> None:\n",
    "        kp_array = np.array([(k.pt[0], k.pt[1], k.size, k.angle, k.response, k.octave, k.class_id) for k in self.kp], dtype=np.float32)\n",
    "        desc_array = np.array(self.desc, dtype=np.float32)\n",
    "        np.save(keypoints_path, kp_array)\n",
    "        np.save(desc_path, desc_array)\n",
    "\n",
    "    def load(self, keypoints_path: str, desc_path: str):\n",
    "        kp_array = np.load(keypoints_path, mmap_mode='r')\n",
    "        desc_array = np.load(desc_path, mmap_mode='r')\n",
    "        keypoints = [cv2.KeyPoint(x=f[0], y=f[1], size=f[2], angle=f[3], response=f[4], octave=int(f[5]), class_id=int(f[6])) for f in kp_array]\n",
    "        return keypoints, desc_array\n",
    "\n",
    "    @staticmethod\n",
    "    def load_from(images_dir: str) -> list['ObjView']:\n",
    "        views = []\n",
    "        detector = cv2.SIFT_create()\n",
    "        image_paths = sorted(glob.glob(os.path.join(images_dir, \"*.png\")), key=lambda s: int(s.split(\"/\")[-1][:-4]))\n",
    "\n",
    "        for image_path in tqdm(image_paths, desc=\"Initializing Object Views from Images\"):\n",
    "            view = ObjView(image_path)\n",
    "            view.detectFeatures(detector)\n",
    "            views.append(view)\n",
    "        return views\n",
    "\n",
    "    def plot_keypoints(self) -> None:\n",
    "        plot = cv2.drawKeypoints(self.img_array, self.kp, self.img_array, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        plt.imshow(plot)\n",
    "        plt.show()\n",
    "\n",
    "views = ObjView.load_from(\"bottle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41a015a-b185-4bc0-8635-5c290853d2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44e9c7d02854703823a403287c058d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching Object Views:   0%|          | 0/570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Scene:\n",
    "    def __init__(self, views: list['ObjView'], root_dir: str) -> None:\n",
    "        self.views = views\n",
    "        self.matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.matches = {}\n",
    "        self.computeMatches()\n",
    "\n",
    "    def computeMatches(self) -> None:\n",
    "        matches_dir = os.path.join(self.root_dir, \"matches\")\n",
    "        os.makedirs(matches_dir, exist_ok=True)\n",
    "        num_views = len(self.views)\n",
    "        for i in tqdm(range(num_views), desc=\"Matching Object Views\"):\n",
    "            for j in range(num_views):\n",
    "                match_path = os.path.join(matches_dir, f\"{self.views[i].img_name}_{self.views[j].img_name}_matches.npy\")\n",
    "                if os.path.exists(match_path):\n",
    "                    self.matches[(self.views[i].img_name, self.views[j].img_name)] = self.load_matches(match_path)\n",
    "                else:\n",
    "                    match = self.matcher.match(self.views[i].desc, self.views[j].desc)\n",
    "                    match = sorted(match, key=lambda x: x.distance)\n",
    "                    self.matches[(self.views[i].img_name, self.views[j].img_name)] = match\n",
    "                    self.save_matches(match_path, match)\n",
    "\n",
    "    def save_matches(self, match_path: str, match: list[cv2.DMatch]) -> None:\n",
    "        match_array = np.array([(m.queryIdx, m.trainIdx, m.distance) for m in match], dtype=np.float32)\n",
    "        np.save(match_path, match_array)\n",
    "\n",
    "    def load_matches(self, match_path: str) -> list[cv2.DMatch]:\n",
    "        match_array = np.load(match_path, mmap_mode='r')\n",
    "        return [cv2.DMatch(int(m[0]), int(m[1]), m[2]) for m in match_array]\n",
    "\n",
    "    def get_matches(self, objview1: 'ObjView', objview2: 'ObjView') -> list[cv2.DMatch]:\n",
    "        return self.matches[(objview1.img_name, objview2.img_name)]\n",
    "\n",
    "    def plot_matches(self, objview1: 'ObjView', objview2: 'ObjView', top_k: int = 100) -> None:\n",
    "        plot = cv2.drawMatches(\n",
    "            objview1.img_array, \n",
    "            objview1.kp, \n",
    "            objview2.img_array, \n",
    "            objview2.kp, \n",
    "            self.matches[(objview1.img_name, objview2.img_name)][:top_k], \n",
    "            None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "        )\n",
    "        plt.imshow(plot)\n",
    "        plt.show()\n",
    "\n",
    "scene = Scene(views, \"bottle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f21d9020-563b-4c8a-bae5-63031b7f598c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 9.99849487e-01,  2.98974735e-04, -1.73468741e-02],\n",
       "        [ 7.79196566e-04,  9.98068783e-01,  6.21135906e-02],\n",
       "        [ 1.73319439e-02, -6.21177583e-02,  9.97918327e-01]]),\n",
       " array([[-0.96313629],\n",
       "        [-0.26901077],\n",
       "        [-0.00130335]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_keypoints_from_indices(keypoints1, index_list1, keypoints2, index_list2):\n",
    "    points1 = np.array([kp.pt for kp in keypoints1])[index_list1]\n",
    "    points2 = np.array([kp.pt for kp in keypoints2])[index_list2]\n",
    "    return points1, points2\n",
    "\n",
    "def remove_outliers_using_F(objview1, objview2, matches):\n",
    "    queryIdx = [m.queryIdx for m in matches]\n",
    "    trainIdx = [m.trainIdx for m in matches]\n",
    "    pixel_points1, pixel_points2 = get_keypoints_from_indices(\n",
    "        keypoints1 = objview1.kp,\n",
    "        keypoints2 = objview2.kp,\n",
    "        index_list1 = queryIdx,\n",
    "        index_list2 = trainIdx\n",
    "    )\n",
    "    F, mask = cv2.findFundamentalMat(\n",
    "        pixel_points1, \n",
    "        pixel_points2, \n",
    "        method = cv2.FM_RANSAC,\n",
    "        ransacReprojThreshold = 0.9,\n",
    "        confidence = 0.99\n",
    "    )\n",
    "    mask = mask.astype(bool).flatten()\n",
    "    inliers1 = np.array(queryIdx)[mask]\n",
    "    inliers2 = np.array(trainIdx)[mask]\n",
    "    return F, inliers1, inliers2\n",
    "\n",
    "def get_camera_from_E(E):\n",
    "    W = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n",
    "    W_t = W.T\n",
    "    u, w, vt = np.linalg.svd(E)\n",
    "    R1 = u @ W @ vt\n",
    "    R2 = u @ W_t @ vt\n",
    "    t1 = u[:, -1].reshape((3, 1))\n",
    "    t2 = - t1\n",
    "    return R1, R2, t1, t2\n",
    "\n",
    "def check_determinant(R):\n",
    "    if np.linalg.det(R) + 1.0 < 1e-9:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def check_triangulation(points, P):\n",
    "    P = np.vstack((P, np.array([0, 0, 0, 1])))\n",
    "    reprojected_points = cv2.perspectiveTransform(src=points[np.newaxis], m=P)\n",
    "    z = reprojected_points[0, :, -1]\n",
    "    if (np.sum(z > 0)/z.shape[0]) < 0.75:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def get_3D_point(u1, P1, u2, P2):\n",
    "    A = np.array([[u1[0] * P1[2, 0] - P1[0, 0], u1[0] * P1[2, 1] - P1[0, 1], u1[0] * P1[2, 2] - P1[0, 2]],\n",
    "                  [u1[1] * P1[2, 0] - P1[1, 0], u1[1] * P1[2, 1] - P1[1, 1], u1[1] * P1[2, 2] - P1[1, 2]],\n",
    "                  [u2[0] * P2[2, 0] - P2[0, 0], u2[0] * P2[2, 1] - P2[0, 1], u2[0] * P2[2, 2] - P2[0, 2]],\n",
    "                  [u2[1] * P2[2, 0] - P2[1, 0], u2[1] * P2[2, 1] - P2[1, 1], u2[1] * P2[2, 2] - P2[1, 2]]])\n",
    "\n",
    "    B = np.array([-(u1[0] * P1[2, 3] - P1[0, 3]),\n",
    "                  -(u1[1] * P1[2, 3] - P1[1, 3]),\n",
    "                  -(u2[0] * P2[2, 3] - P2[0, 3]),\n",
    "                  -(u2[1] * P2[2, 3] - P2[1, 3])])\n",
    "\n",
    "    X = cv2.solve(A, B, flags=cv2.DECOMP_SVD)\n",
    "    return X[1]\n",
    "\n",
    "def triangulate(objview1, objview2, matches, K, R, t):\n",
    "\n",
    "    K_inv = np.linalg.inv(K)\n",
    "    P1 = np.hstack((objview1.R, objview1.t))\n",
    "    P2 = np.hstack((R, t))\n",
    "\n",
    "    queryIdx = [m.queryIdx for m in matches]\n",
    "    trainIdx = [m.trainIdx for m in matches]\n",
    "\n",
    "    # only reconstructs the inlier points filtered using the fundamental matrix\n",
    "    pixel_points1, pixel_points2 = get_keypoints_from_indices(\n",
    "        keypoints1 = objview1.kp,\n",
    "        keypoints2 = objview2.kp,\n",
    "        index_list1 = queryIdx,\n",
    "        index_list2 = trainIdx\n",
    "    )\n",
    "\n",
    "    # convert 2D pixel points to homogeneous coordinates\n",
    "    pixel_points1 = cv2.convertPointsToHomogeneous(pixel_points1)[:, 0, :]\n",
    "    pixel_points2 = cv2.convertPointsToHomogeneous(pixel_points2)[:, 0, :]\n",
    "\n",
    "    reprojection_error = []\n",
    "\n",
    "    points_3D = np.zeros((0, 3))\n",
    "\n",
    "    for i in range(len(pixel_points1)):\n",
    "        u1 = pixel_points1[i, :]\n",
    "        u2 = pixel_points2[i, :]\n",
    "\n",
    "        u1_normalized = K_inv.dot(u1)\n",
    "        u2_normalized = K_inv.dot(u2)\n",
    "\n",
    "        point_3D = get_3D_point(u1_normalized, P1, u2_normalized, P2)\n",
    "\n",
    "        error = calculate_reprojection_error(point_3D, u2[0:2], K, R, t)\n",
    "        reprojection_error.append(error)\n",
    "\n",
    "        points_3D = np.concatenate((points_3D, point_3D.T), axis=0)\n",
    "\n",
    "    return np.mean(reprojection_error), points_3D\n",
    "\n",
    "def calculate_reprojection_error(point_3D, point_2D, K, R, t):\n",
    "    reprojected_point = K.dot(R.dot(point_3D) + t)\n",
    "    reprojected_point = cv2.convertPointsFromHomogeneous(reprojected_point.T)[:, 0, :].T\n",
    "    error = np.linalg.norm(point_2D.reshape((2, 1)) - reprojected_point)\n",
    "    return error\n",
    "\n",
    "def check_pose(objview1, objview2, matches, E, K):\n",
    "\n",
    "    R1, R2, t1, t2 = get_camera_from_E(E)  # decompose E\n",
    "    if not check_determinant(R1):\n",
    "        R1, R2, t1, t2 = get_camera_from_E(-E)  # change sign of E if R1 fails the determinant test\n",
    "    reprojection_error, points_3D = triangulate(objview1, objview2, matches, K, R1, t1)\n",
    "\n",
    "    if reprojection_error > 100.0 or not check_triangulation(points_3D, np.hstack((R1, t1))):\n",
    "\n",
    "\n",
    "        reprojection_error, points_3D = triangulate(objview1, objview2, matches, K, R1, t2)\n",
    "        if reprojection_error > 100.0 or not check_triangulation(points_3D, np.hstack((R1, t2))):\n",
    "\n",
    "            reprojection_error, points_3D = triangulate(objview1, objview2, matches, K, R2, t1)\n",
    "            if reprojection_error > 100.0 or not check_triangulation(points_3D, np.hstack((R2, t1))):\n",
    "\n",
    "                return R2, t2\n",
    "\n",
    "            else:\n",
    "                return R2, t1\n",
    "\n",
    "        else:\n",
    "            return R1, t2\n",
    "\n",
    "    else:\n",
    "        return R1, t1\n",
    "\n",
    "objview1 = views[0]\n",
    "objview2 = views[1]\n",
    "matches = scene.matches[(ObjView1.img_name, ObjView2.img_name)]\n",
    "\n",
    "F, inliers1, inliers2 = remove_outliers_using_F(objview1, objview2, matches)\n",
    "K = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "E = K.T @ F @ K\n",
    "objview1, objview2 = check_pose(objview1, objview2, matches, E, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89872b4f-df86-448b-8db0-decf0ac238ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pose(self, objview1: ObjView, objview2: Optional['ObjView'] = None, is_baseline=False):\n",
    "\n",
    "        if is_baseline and view2:\n",
    "\n",
    "            match_object = self.matches[(view1.name, view2.name)]\n",
    "            baseline_pose = Baseline(view1, view2, match_object)\n",
    "            view2.R, view2.t = baseline_pose.get_pose(self.K)\n",
    "\n",
    "            rpe1, rpe2 = self.triangulate(view1, view2)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            view1.R, view1.t = self.compute_pose_PNP(view1)\n",
    "            errors = []\n",
    "\n",
    "            # reconstruct unreconstructed points from all of the previous views\n",
    "            for i, old_view in enumerate(self.done):\n",
    "\n",
    "                match_object = self.matches[(old_view.name, view1.name)]\n",
    "                _ = remove_outliers_using_F(old_view, view1, match_object)\n",
    "                self.remove_mapped_points(match_object, i)\n",
    "                _, rpe = self.triangulate(old_view, view1)\n",
    "                errors += rpe\n",
    "\n",
    "            self.done.append(view1)\n",
    "            self.errors.append(np.mean(errors))\n",
    "\n",
    "\n",
    "baseline_view1, baseline_view2 = views[0], views[1]\n",
    "compute_pose(view1=baseline_view1, view2=baseline_view2, is_baseline=True)\n",
    "# self.plot_points()\n",
    "\n",
    "# for i in range(2, len(self.views)):\n",
    "\n",
    "    # logging.info(\"Computing pose and reconstructing points for view %d\", i+1)\n",
    "    # self.compute_pose(view1=self.views[i])\n",
    "    # logging.info(\"Mean reprojection error for %d images is %f\", i+1, self.errors[i])\n",
    "    # self.plot_points()\n",
    "    # logging.info(\"Points plotted for %d views\", i+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
